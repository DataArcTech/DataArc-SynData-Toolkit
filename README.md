# DataArc SynData Toolkit

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Framework: uv](https://img.shields.io/badge/Package_Manager-uv-42b983.svg)](https://github.com/astral-sh/uv)
[![Pydantic v2](https://img.shields.io/badge/Pydantic-v2-ffa000.svg)](https://docs.pydantic.dev/)

*A modular, highly user-friendly synthetic data generation toolkit supporting multi-source, multi-language data synthesis.*

### Easily synthesize training data for LLMs with zero-code [CLI](#:rocket:-Quick-Start) and [GUI](#:desktop_computer:-Synthesizing-Data-with-GUI) !

:book: [ **English** | [ä¸­æ–‡](./README_zh.md) ]

## :dart: Project Overview

**DataArc SynData Toolkit** is a synthetic data generation toolkit developed and open-sourced by DataArcTech (https://www.dataarctech.com/) and International Digital Economy Academy (https://www.idea.edu.cn/). It enables users to generate customized training data in one step through simple configuration files based on their requirements.

## :bulb: Key Features

- **Extremely Simple Usage**: Synthesize data with [a single command](#3-Synthesize-Data) and a configuration file. [GUI](##:desktop_computer:-Synthesizing-Data-with-GUI) is also provided for easy operations.
- **Support for Multi-Source Synthetic Data**:
  - **Local Synthesis**: Support for generating data based on local corpora.
  - **Huggingface Integration**: Automatically screens and retrieves data from Huggingface.
  - **Model Distillation**: Enable synthetic data generation through model distillation.
- **Integrated Post-Training Module**: End-to-end model training workflows powered by verl, supporting SFT and GRPO.
- **Multilingual Support**: Supports English and various low-resource languages.
- **Multi-Provider Model Support**: Works with local deployment, OpenAI APIs, and more.
- **Highly Extensible**: The entire synthetic data workflow is modular, allowing developers to flexibly customize them.

## :movie_camera: Demo

We provide a highly user friendly GUI for everything. Watch a two-minute demo to understand **DataArc SynData Toolkit**.

## :microscope: Performance

| Model                       | Medical | Finance | Law    |
|-----------------------------|---------|---------|--------|
| Qwen-2.5-7B-Instruct        | 42.34%  | 52.91%  | 19.80% |
| Trained with Synthetic Data | 64.57%  | 73.93%  | 42.80% |

A few lines of code deliver over 20% performance improvements.

## :notebook: Changelog

[25/11/17] ðŸŽ‰We open-sourced our synthetic data platform.  
[25/11/27] We added **parallel processing module** to significantly accelerate the synthetic data generation pipeline.  
[25/11/28] We added **intermediate result saving**, allowing users to resume from the last successful stage** instead of restarting the entire pipeline â€” a major **token saver**.  
[25/12/xx] ðŸ”¥Major upgrade:
- **Frontendâ€“Backend Separation**: **DataArc SynData Toolkit** now adopts a fully frontendâ€“backend separated architecture, featuring a **FastAPI backend** (REST APIs + SSE streaming for real-time progress) and a standalone **React** frontend for improved visualization, usability, and scalability.
- **Post-Training Support via verl**: Introduced an integrated post-training module powered by **verl**, enabling end-to-end model training workflows including **SFT** and **GRPO** on synthesized data.
- **Multilingual Expansion**: Added support for generating **Arabic** datasets, leveraging an Arabic translation model to produce fully localized synthetic data outputs.

> [!TIP]
>
> If you cannot use the latest feature, please pull the latest code.

## :factory: DataArc SynData Toolkit Pipeline

**DataArc SynData Toolkit** is designed to synthesize data in a modular pipeline, allowing users to customize the strategies and implementation methods of each step. The main components include:

- **Synthetic Data Generation**: Generate data through methods such as local synthesis, Huggingface dataset retrieval, and model distillation.
  - Developers can inherit [BaseTaskConfig](./sdgsystem/configs/config.py) and [BaseTaskExecutor](./sdgsystem/tasks/base.py) to customize the generation task.
- **Data Filtering and Rewriting**: Filter and rewrite initially synthesized data according to the target model's requirements.
  - Developers can inherit [BaseRewriteConfig](./sdgsystem/configs/config.py) and [BaseRewriter](./sdgsystem/generation/rewriter.py) to customize the rewrite method for synthetic data (or no rewriting).

![dataarc-sdg_pipeline](assets/dataarc-syndata-toolkit_pipeline.png)

By decoupling modules, developers can achieve flexible customization of functional modules based on specific needs.

## :jigsaw: Use Cases

We provide [three different use cases](docs/USE_CASES.md) that sythesize data through **DataArc SynData Toolkit**.

## :file_folder: Project Structure

```
DataArc-SynData-Toolkit/
â”œâ”€â”€ configs/                        # Configuration Examples
â”‚   â”œâ”€â”€ example.yaml                # SDG configuration example
â”‚   â”œâ”€â”€ sft_example.yaml            # SFT training configuration
â”‚   â””â”€â”€ grpo_example.yaml           # GRPO training configuration
â”‚
â”œâ”€â”€ sdgsystem/                      # Core Implementation
â”‚   â”œâ”€â”€ app/                        # FastAPI Backend (REST + SSE)
â”‚   â”‚   â”œâ”€â”€ api/                    # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ jobs.py             # job management endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic schemas
â”‚   â”‚   â”‚   â””â”€â”€ router.py           # API router
â”‚   â”‚   â”œâ”€â”€ core/                   # Core backend components
â”‚   â”‚   â”‚   â”œâ”€â”€ job_manager.py      # job lifecycle management
â”‚   â”‚   â”‚   â”œâ”€â”€ progress.py         # progress reporter for SSE
â”‚   â”‚   â”‚   â””â”€â”€ sse.py              # Server-Sent Events utilities
â”‚   â”‚   â”œâ”€â”€ services/               # Business logic services
â”‚   â”‚   â”‚   â””â”€â”€ sdg_service.py      # SDG pipeline service wrapper
â”‚   â”‚   â””â”€â”€ main.py                 # FastAPI application entry
â”‚   â”‚
â”‚   â”œâ”€â”€ configs/                    # Configuration Module
â”‚   â”‚   â”œâ”€â”€ config.py               # configuration parsing
â”‚   â”‚   â””â”€â”€ constants.py            # default arguments
â”‚   â”‚
â”‚   â”œâ”€â”€ dataset/                    # Dataset Module
â”‚   â”‚   â”œâ”€â”€ dataset.py              # dataset class
â”‚   â”‚   â””â”€â”€ process.py              # quality control and formatting
â”‚   â”‚
â”‚   â”œâ”€â”€ distillation/               # Model Distillation
â”‚   â”‚   â”œâ”€â”€ base.py                 # base distillation class
â”‚   â”‚   â”œâ”€â”€ sdg_distill.py          # SDG distillation implementation
â”‚   â”‚   â”œâ”€â”€ self_instruct.py        # self-instruct method
â”‚   â”‚   â””â”€â”€ evol_instruct.py        # evol-instruct method
â”‚   â”‚
â”‚   â”œâ”€â”€ documents/                  # Document Processing
â”‚   â”‚   â”œâ”€â”€ load.py                 # document loading
â”‚   â”‚   â”œâ”€â”€ parse.py                # document parsing
â”‚   â”‚   â”œâ”€â”€ chunk.py                # text chunking
â”‚   â”‚   â””â”€â”€ retrieve.py             # passage retrieval (BM25)
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                 # Evaluation Module
â”‚   â”‚   â”œâ”€â”€ answer_comparison.py    # answer comparison methods
â”‚   â”‚   â””â”€â”€ evaluator.py            # sample evaluator
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/                 # Generation Module
â”‚   â”‚   â”œâ”€â”€ base.py                 # base generator with validation
â”‚   â”‚   â”œâ”€â”€ generator.py            # data generator
â”‚   â”‚   â””â”€â”€ rewriter.py             # data rewriter
â”‚   â”‚
â”‚   â”œâ”€â”€ huggingface/                # HuggingFace Integration
â”‚   â”‚   â””â”€â”€ crawl.py                # dataset crawling from HF
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                     # Model Interaction Module
â”‚   â”‚   â”œâ”€â”€ postprocess/            # response postprocessing
â”‚   â”‚   â”‚   â”œâ”€â”€ majority_voting.py  # majority voting implementation
â”‚   â”‚   â”‚   â””â”€â”€ processor.py        # postprocessor orchestration
â”‚   â”‚   â”œâ”€â”€ answer_extraction.py    # answer extraction from responses
â”‚   â”‚   â”œâ”€â”€ client.py               # unified model client
â”‚   â”‚   â”œâ”€â”€ models.py               # model deployment adapters
â”‚   â”‚   â”œâ”€â”€ processor_arguments.py  # postprocessor arguments
â”‚   â”‚   â””â”€â”€ usage_counter.py        # token/time usage tracking
â”‚   â”‚
â”‚   â”œâ”€â”€ tasks/                      # Task Execution Module
â”‚   â”‚   â”œâ”€â”€ base.py                 # base executor class
â”‚   â”‚   â”œâ”€â”€ local.py                # local document-based task
â”‚   â”‚   â”œâ”€â”€ web.py                  # HuggingFace web task
â”‚   â”‚   â”œâ”€â”€ distill.py              # distillation task
â”‚   â”‚   â””â”€â”€ task_executor.py        # unified task executor
â”‚   â”‚
â”‚   â”œâ”€â”€ trainer/                    # Model Training Module (verl)
â”‚   â”‚   â”œâ”€â”€ methods/                # training method implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ sft.py              # SFT training method
â”‚   â”‚   â”‚   â””â”€â”€ grpo.py             # GRPO training method
â”‚   â”‚   â”œâ”€â”€ config.py               # training configuration
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py   # training data preprocessing
â”‚   â”‚   â””â”€â”€ launcher.py             # training job launcher
â”‚   â”‚
â”‚   â”œâ”€â”€ translation/                # Multilingual Support
â”‚   â”‚   â””â”€â”€ translator.py           # translation utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ webui/                      # React Frontend
â”‚   â”‚
â”‚   â”œâ”€â”€ buffer.py                   # checkpoint/buffer management
â”‚   â”œâ”€â”€ cli.py                      # CLI entry point
â”‚   â”œâ”€â”€ parallel.py                 # parallel processing utilities
â”‚   â”œâ”€â”€ pipeline.py                 # main SDG pipeline
â”‚   â”œâ”€â”€ prompts.py                  # LLM prompts
â”‚   â””â”€â”€ utils.py                    # utility functions
â”‚
â”œâ”€â”€ verl/                           # verl Training Framework
â”‚
â”œâ”€â”€ docs/                           # Documentation
â”‚
â”œâ”€â”€ pyproject.toml                  # project dependencies
â””â”€â”€ README.md                       # project documentation
```

## :rocket: Quick Start

### 1. Install DataArc SynData Toolkit

```shell
# 1. Clone the repository
git clone https://github.com/DataArcTech/DataArc-SynData-Toolkit.git
cd DataArc-SynData-Toolkit

# 2. Install uv if not already installed
pip install uv

# 3. Install dependencies 
uv sync
```

For hardware requirements and dependencies detail, please refer to [dependency and installation guide](/docs/DEPENDENCIES.md).

### 2. Configuration

Please refer to the [example configuration file](./configs/example.yaml) and modify the configuration based on your requirements.

### 3. Synthesize Data

Run through CLI: 

Create a .env file and specified the following fields.

```shell
API_KEY=sk-xxx   # your api key
BASE_URL=https://api.openai.com/v1  # Optional: your base url
```

And run following command.

```shell
uv run sdg generate configs/example.yaml  # or change to your .yaml file
```

## :twisted_rightwards_arrows: Training with Synthesized Data

**DataArc SynData Toolkit** integrates an end-to-end model training module powered by [verl](https://github.com/volcengine/verl), enabling you to train models directly on your synthesized data. We support two training methods: **SFT (Supervised Fine-Tuning)** and **GRPO (Group Relative Policy Optimization)**

### Quick Start with CLI

#### 1. Prepare Your Configuration

Create a training configuration file based on the [SFT Configuration Example](./configs/sft_example.yaml) or [GRPO Configuration Example](./configs/grpo_example.yaml).

#### 2. Run Training

```shell
# SFT training
uv run sdg train configs/sft.yaml

# GRPO training
uv run sdg train configs/grpo.yaml
```

For detailed configuration options, refer to the example YAML files.

## :desktop_computer: Run with GUI

Start FastAPI server with following command.

```shell
uv run fastapi dev sdgsystem/app/main.py
```

Open another terminal and build frontend with following command.

```shell
cd sdgsystem/webui

# Install dependencies
pnpm install

# Start development server
pnpm dev
```

If you have any doubt about regrading our Web UI, check our [Web UI document](/sdgsystem/webui/README.md).

## :date: Schedule for the Next Release

- **Multi-modal Dataset Synthesizing**: Support synthesize data through image.

## :handshake: Contributing

We welcome contributions!
