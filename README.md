# DataArc SynData Toolkit

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/) [![Framework: uv](https://img.shields.io/badge/Package_Manager-uv-42b983.svg)](https://github.com/astral-sh/uv) [![Gradio UI](https://img.shields.io/badge/GUI-Gradio-ff6f00.svg)](https://github.com/gradio-app/gradio) [![Pydantic v2](https://img.shields.io/badge/Pydantic-v2-ffa000.svg)](https://docs.pydantic.dev/)

*A modular, highly user-friendly synthetic data generation toolkit supporting multi-source, multi-language data synthesis.*

### Easily synthesize training data for LLMs with zero-code [CLI](#:rocket:-Quick-Start) and [GUI](#:desktop_computer:-Synthesizing-Data-with-GUI) !

:book: [ **English** | [ä¸­æ–‡](./README_zh.md) ]

  

## :dart: Project Overview

**DataArc SynData Toolkit** is a synthetic data generation toolkit developed and open-sourced by DataArc. It enables users to generate customized training data in one step through simple configuration files based on their requirements.



## :bulb: Key Features

- **Extremely Simple Usage**: Synthesize data with [a single command](#3-Synthesize-Data) and a configuration file. [Gradio UI](##:desktop_computer:-Synthesizing-Data-with-GUI) is also provided for easy operations.
- **Support for Multi-Source Synthetic Data**:
  - **Local Synthesis**: Support for generating data based on local corpora.
  - **Huggingface Integration**: Automatically screens and retrieves data from Huggingface.
  - **Model Distillation**: Enable synthetic data generation through model distillation.
- **Multilingual Support**: Supports English and various low-resource languages.
- **Multi-Provider Model Support**: Works with local deployment, OpenAI APIs, and more.
- **Highly Extensible**: The entire synthetic data workflow is modular, allowing developers to flexibly customize them.


## ðŸ”¬ Performance

| Model                       | Medical | Finance | Law   |
|----------------------------|---------|---------|-------|
| Qwen-2.5-7B-Instruct       | 42.34%  | 52.91%   | 19.80% |
| Trained with Synthetic Data | 64.57%  | 73.93%  | 42.80% |

A few lines of code deliver over 20% performance improvements.

## :notebook: Changelog

[25/11/17] We open-sourced our synthetic data platform.

> [!TIP]
>
> If you cannot use the latest feature, please pull the latest code.



## :factory: DataArc SynData Toolkit Pipeline

**DataArc SynData Toolkit** is designed to synthesize data in a modular pipeline, allowing users to customize the strategies and implementation methods of each step. The main components include:

- **Synthetic Data Generation**: Generate data through methods such as local synthesis, Huggingface dataset retrieval, and model distillation.
  - Developers can inherit [BaseTaskConfig](./sdgsystem/configs/config.py) and [BaseTaskExecutor](./sdgsystem/tasks/base.py) to customize the generation task.
- **Data Filtering and Rewriting**: Filter and rewrite initially synthesized data according to the target model's requirements.
  - Developers can inherit [BaseRewriteConfig](./sdgsystem/configs/config.py) and [BaseRewriter](./sdgsystem/generation/rewriter.py) to customize the rewrite method for synthetic data (or no rewriting).

![dataarc-sdg_pipeline](assets/dataarc-syndata-toolkit_pipeline.png)

By decoupling modules, developers can achieve flexible customization of functional modules based on specific needs.



## :jigsaw: Use Cases

We provide [three different use cases](examples/README.md) that sythesize data through **DataArc SynData Toolkit**.



## :file_folder: Project Structure

```
dataarc-sdg/
â”œâ”€â”€ configs/						# Configuration Examples
â”‚   â”œâ”€â”€ example.yaml				# example YAML file
|
â”œâ”€â”€ sdgsystem/						# Implementation of Functions
â”‚   â”œâ”€â”€ configs/					# Configuration Module
|	|	â”œâ”€â”€ config.py				# configuration parsing
|	|	â””â”€â”€ constants.py			# default arguments
|
â”‚   â”œâ”€â”€ dataset/					# Dataset Module
|	|	â”œâ”€â”€ dataset.py				# dataset class
|	|	â””â”€â”€ process.py				# quality control and formatting
|
â”‚   â”œâ”€â”€ huggingface/				# Huggingface Crawling
â”‚   â”œâ”€â”€ documents/					# Retrieve/Parsing/Chunk of Local Corpora
â”‚   â”œâ”€â”€ distillation/				# Model Distillation
|
â”‚   â”œâ”€â”€ evaluation/					# Evaluation Module
|	|	â”œâ”€â”€ answer_comparison.py	# answer comparison
|	|	â”œâ”€â”€ evaluator.py			# evaluator
|
â”‚   â”œâ”€â”€ generation/					# Generation Module
|	|	â”œâ”€â”€ base.py					# base class of generation
|	|	â”œâ”€â”€ generator.py			# data generator
|	|	â”œâ”€â”€ rewriter.py				# data rewriter
|
â”‚   â”œâ”€â”€ models/						# Model Interaction Module
|	|	â”œâ”€â”€ postprocess/			# postprocess of model responses (e.g. majority voting)
|	|	â”œâ”€â”€ answer_extraction.py	# answer extraction from responses
|	|	â”œâ”€â”€ models.py				# model deployment and chatting
|	|	â”œâ”€â”€ processor_arguments.py	# arguments of post-processor
|	|	â”œâ”€â”€ client.py				# client for interacting with models
|
â”‚   â”œâ”€â”€ tasks/						# Generation Task Execution Module
|	|	â”œâ”€â”€ base.py					# base class of executor
|	|	â”œâ”€â”€ (local/web/distill).py	# executor for different sources/route
|	|	â”œâ”€â”€ total_executor.py		# total executor
|
â”‚   â”œâ”€â”€ translation/				# Support for Low-Resource Languages
|
â”‚   â”œâ”€â”€ cli.py						# API for project functions
â”‚   â”œâ”€â”€ pipeline.py					# pipeline of data synthesis
â”‚   â”œâ”€â”€ prompts.py					# prompts used in project
â”‚   â”œâ”€â”€ token_counter.py			# token usage estimation
â”‚   â””â”€â”€ utils.py					# other function utils
|
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ datasets/					# training datasets
|	|	â”œâ”€â”€ examples/				  # training examples
|	|	â”œâ”€â”€ scripts/				  # scripts
|	|	â””â”€â”€ verl/			        # training module by verl
|
â”œâ”€â”€ tests/							# Test Suite
|
â”œâ”€â”€ app.py							# gradio UI
â”œâ”€â”€ pyproject.toml					# project dependencies
â””â”€â”€ README.md						# project documentation
```



## :rocket: Quick Start

### 1. Install DataArc SynData Toolkit

```shell
# 1. Clone the repository
git clone https://github.com/DataArcTech/DataArc-SynData-Toolkit.git
cd DataArc-SynData-Toolkit

# 2. Install uv if not already installed
pip install uv

# 3. Install dependencies 
uv sync
```

For hardware requirements and dependencies detail, please refer to [dependency and installation guide](DEPENDENCIES.md).

### 2. Configuration

Please refer to the [example configuration file](./configs/example.yaml) and modify the configuration based on your requirements.

### 3. Synthesize Data

Run through CLI: 

Create a .env file and specified the following fields.

```shell
OPENAI_API_KEY=sk-xxx   # your api key
OPENAI_BASE_URL=https://api.openai.com/v1  # Optional: your base url
```

And run following command.

```shell
uv run sdg configs/example.yaml  # or change to your .yaml file
```

## :twisted_rightwards_arrows: Training with Synthesized Data

Prepare your synthesized data at datasets/. Here is an example of LoRA fine-tuning with gsm8k dataset on Qwen2.5-0.5B:

```shell
cd train
bash examples/sft/gsm8k/run_qwen_05_peft.sh
```

## :desktop_computer: Synthesizing Data with GUI

The UI is powered by [Gradio](https://github.com/gradio-app/gradio). Build with following command.

```shell
uv run python app.py
```

![](./assets/frontend.png)



## :wrench: Configuration System

DataArc-SDG is configured using a flexible YAML file, please check our provided [example yaml file](configs/example.yaml).



## :date: Schedule for the Next Release

- **Arabic Support**: Support for generating Arabic synthetic data.
- **Custom Data Sources**: Support for custom addition of data sources and corresponding protocol file conversion.
- **Model Fine-tuning Module**: Support fine-tuning models using synthetic data within the pipeline.



## :handshake: Contributing

We welcome contributions!
